{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "import pprint\n",
    "import collections\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures, TrigramCollocationFinder, TrigramAssocMeasures\n",
    "from nltk.tag import DefaultTagger, UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import webtext\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monty = webtext.raw('grail.txt')\n",
    "assert_is_instance(monty, str)\n",
    "assert_equal(len(monty), 65003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text_str):\n",
    "    '''\n",
    "    Tokenizes the text string by words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: A string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings\n",
    "    '''\n",
    "    \n",
    "    tokens=word_tokenize(text_str)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok = tokenize(monty)\n",
    "assert_is_instance(tok,list)\n",
    "assert_true(all(isinstance(t, str) for t in tok))\n",
    "assert_equal(len(tok), 16450)\n",
    "assert_equal(tok[:10], ['SCENE', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop'])\n",
    "assert_equal(tok[51:55], ['King', 'of', 'the', 'Britons'])\n",
    "assert_equal(tok[507:511], ['African', 'swallows', 'are', 'non-migratory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations: bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def x_bigrams(tokens, x):\n",
    "    '''\n",
    "    Find the x best bi-grams given tokens (a list of strings) and x which will \n",
    "    tell you how many bi-grams to return.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: A list of strings\n",
    "    x: An integer\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ls_bigram: A list of tuples, with the tuples being of the form (str, str).\n",
    "    '''\n",
    "    \n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(tokens)\n",
    "    ls_bigram = finder.nbest(bigram_measures.pmi, x)\n",
    "    return ls_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = x_bigrams(tok, 20)\n",
    "assert_is_instance(bigrams, list)\n",
    "assert_true(all(isinstance(b, tuple) for b in bigrams))\n",
    "assert_true(len(bigrams), 20)\n",
    "assert_equal(bigrams, [(\"'Til\", 'Recently'), (\"'To\", 'whoever'),\n",
    "                       ('Anybody', 'armed'), ('Attila', 'raised'),\n",
    "                       ('Badon', 'Hill'), ('Bon', 'magne'), ('Chapter', 'Two'),\n",
    "                       ('Clark', 'Gable'), ('Divine', 'Providence'),\n",
    "                       ('Great', 'scott'), ('Most', 'kind'),\n",
    "                       ('Olfin', 'Bedwere'), ('Recently', 'Said'),\n",
    "                       ('Thou', 'hast'), ('Thy', 'mer'), ('Too', 'late'),\n",
    "                       ('Uther', 'Pendragon'), ('absolutely', 'necessary'),\n",
    "                       ('advancing', 'behaviour'),\n",
    "                       ('anarcho-syndicalist', 'commune')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations: trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def x_trigrams(tokens, x):\n",
    "    '''\n",
    "    Find the x best tri-grams given tokens (a list of strings) and x which will \n",
    "    tell you how many tri-grams to return.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: A list of strings\n",
    "    x: An integer\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tri_list: A list of tuples, with the tuples being of the \n",
    "    form (str, str, str).\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    trigram_measures = TrigramAssocMeasures()\n",
    "    finder = TrigramCollocationFinder.from_words(tokens)\n",
    "    tri_list = finder.nbest(trigram_measures.pmi, x)\n",
    "    return tri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = x_trigrams(tok, 5)\n",
    "assert_is_instance(trigrams, list)\n",
    "assert_true(all(isinstance(t, tuple) for t in trigrams))\n",
    "assert_true(len(trigrams), 5)\n",
    "assert_equal(trigrams, [(\"'Til\", 'Recently', 'Said'),\n",
    "                        (\"'To\", 'whoever', 'finds'), \n",
    "                        ('Thou', 'hast', 'vouchsafed'),\n",
    "                        ('basic', 'medical', 'training'),\n",
    "                        ('dorsal', 'guiding', 'feathers')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tagging(tokens, default = True):\n",
    "    '''\n",
    "    Performs POS tagging with the tagger determined by the boolean 'default'.    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: a list of strings\n",
    "    default: a boolean \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tagged: a list of tuples, with the tuples taking the form of (str, str)\n",
    "    '''\n",
    "    \n",
    "    if default==True:\n",
    "        ptgs = pos_tag(tokens)\n",
    "    elif default==False:\n",
    "        ptgs=pos_tag(tokens, tagset='universal')\n",
    "    return ptgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni = tagging(tok, default = False)\n",
    "assert_is_instance(uni, list)\n",
    "assert_true(all(isinstance(u, tuple) for u in uni))\n",
    "assert_true(len(uni), 16450)\n",
    "assert_equal(uni[745:760], [('DEAD', 'NOUN'), ('PERSON', 'NOUN'),\n",
    "                            (':', '.'), ('I', 'PRON'), (\"'m\", 'VERB'),\n",
    "                            ('not', 'ADV'), ('dead', 'ADJ'), ('!', '.'),\n",
    "                            ('CART-MASTER', 'NOUN'), (':', '.'),\n",
    "                            ('What', 'PRON'), ('?', '.'), ('CUSTOMER', 'NOUN'),\n",
    "                            (':', '.'), ('Nothing', 'NOUN')])\n",
    "\n",
    "not_uni = tagging(tok)\n",
    "assert_is_instance(not_uni, list)\n",
    "assert_true(all(isinstance(n, tuple) for n in not_uni))\n",
    "assert_true(len(not_uni), 16450)\n",
    "assert_equal(not_uni[1503:1525], [('We', 'PRP'), (\"'re\", 'VBP'), ('an', 'DT'),\n",
    "                                  ('anarcho-syndicalist', 'JJ'),\n",
    "                                  ('commune', 'NN'), ('.', '.'), ('We', 'PRP'),\n",
    "                                  ('take', 'VBP'), ('it', 'PRP'), ('in', 'IN'),\n",
    "                                  ('turns', 'VBZ'), ('to', 'TO'), ('act', 'VB'),\n",
    "                                  ('as', 'IN'), ('a', 'DT'), ('sort', 'NN'),\n",
    "                                  ('of', 'IN'), ('executive', 'JJ'),\n",
    "                                  ('officer', 'NN'), ('for', 'IN'),\n",
    "                                  ('the', 'DT'), ('week', 'NN')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagged Text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_tx_ext(tokens,n):\n",
    "    '''\n",
    "    Takes in tokens and returns a list of tokens that are either nouns\n",
    "    or adjectives as well as a list of tuples of the most common adjectives\n",
    "    or nouns with their number of occurances.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: A list of strings.\n",
    "    n: An integer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of ext_tag and common where these two arguments have the following\n",
    "    structure:\n",
    "    ext_tag: A list of strings.\n",
    "    common: A list of tuples of the form (str, int)\n",
    "    '''\n",
    "    \n",
    "    rgxs = re.compile(r'(JJ|NN)')\n",
    "    ptgs = pos_tag(tokens)\n",
    "    trms = [tkn[0] for tkn in ptgs if re.match(rgxs, tkn[1])]\n",
    "    common=collections.Counter(ex_tags).most_common(n)\n",
    "    return trms,common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_tags, com = tag_tx_ext(tok, 13)\n",
    "assert_is_instance(ex_tags, list)\n",
    "assert_true(all(isinstance(ex, str) for ex in ex_tags))\n",
    "assert_true(len(ex_tags), 5323)\n",
    "assert_equal(ex_tags[603:620], ['BLACK', 'KNIGHT', 'Aagh', 'GREEN', 'KNIGHT',\n",
    "                                '[', 'King', 'Arthur', 'music', ']', 'Ooh',\n",
    "                                '[', 'music', ']', 'BLACK','KNIGHT', 'Aaagh'])\n",
    "\n",
    "assert_equal(ex_tags[1000:1010], ['Burn', 'BEDEVERE', 'Quiet', 'Quiet', 'Quiet',\n",
    "                                  'Quiet', 'ways', 'witch', 'VILLAGER', 'Are'])\n",
    "\n",
    "assert_is_instance(com, list)\n",
    "assert_true(all(isinstance(c, tuple) for c in com))\n",
    "assert_true(len(com), 13)\n",
    "assert_equal(com, [(']', 296), ('[', 285), ('ARTHUR', 220), ('LAUNCELOT', 71),\n",
    "                   ('KNIGHT', 68), ('GALAHAD', 67), ('FATHER', 63),\n",
    "                   ('BEDEVERE', 60), ('HEAD', 54), ('GUARD', 53),\n",
    "                   ('Sir', 51), ('VILLAGER', 47), ('boom', 45)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
