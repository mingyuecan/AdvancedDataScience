{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import tweepy as tw\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true, assert_almost_equal\n",
    "from numpy.testing import assert_array_equal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_twitter_api(cred_file):\n",
    "    \n",
    "    # Order: Access Token, Access Token Secret, Consumer Key, Consumer SecretAccess\n",
    "    with open(cred_file) as fin:\n",
    "        tokens = [line.rstrip('\\n') for line in fin if not line.startswith('#')]\n",
    "\n",
    "    auth = tw.OAuthHandler(tokens[2], tokens[3])\n",
    "    auth.set_access_token(tokens[0], tokens[1])\n",
    "\n",
    "    return tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = connect_twitter_api('twitter.cred')\n",
    "assert_equal(api.get_user('katyperry').screen_name, 'katyperry')\n",
    "assert_equal(api.get_user('justinbieber').created_at.strftime('%Y %m %d %H %M %S'), '2009 03 28 16 41 22')\n",
    "assert_equal(api.get_user('BarackObama').name, 'Barack Obama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples as tws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pos_neg_tweets(corpus):\n",
    "    '''\n",
    "    Creates a training set from twitter_samples corpus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus: The nltk.corpus.twitter_samples corpus.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (data, targets)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pos_tweets = np.array(corpus.strings('positive_tweets.json'))\n",
    "    neg_tweets = np.array(corpus.strings('negative_tweets.json'))\n",
    "    pos_labels = np.ones(pos_tweets.shape[0])\n",
    "    neg_labels = np.zeros(neg_tweets.shape[0])\n",
    "    data = np.concatenate((pos_tweets, neg_tweets), axis = 0)\n",
    "    targets = np.concatenate((pos_labels, neg_labels), axis=0)\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, targets = get_pos_neg_tweets(tws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_is_instance(data, np.ndarray)\n",
    "assert_is_instance(targets, np.ndarray)\n",
    "assert_equal(len(data), 10000)\n",
    "assert_equal(len(targets), 10000)\n",
    "assert_array_equal(\n",
    "    data[:5],\n",
    "    [\n",
    "        '#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top '\n",
    "            'engaged members in my community this week :)',\n",
    "        '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234'\n",
    "            ' and we will be able to assist you :) Many thanks!',\n",
    "        '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing '\n",
    "            'track. When are you in Scotland?!',\n",
    "        '@97sides CONGRATS :)',\n",
    "        'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark '\n",
    "            'on my fb profile :) in 15 days'\n",
    "        ]\n",
    "    )\n",
    "assert_array_equal(\n",
    "    data[5000:5005],\n",
    "    [\n",
    "        'hopeless for tmr :(',\n",
    "        \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in \"\n",
    "            \"2 months :(\",\n",
    "        '@Hegelbon That heart sliding into the waste basket. :(',\n",
    "        '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
    "        'Dang starting next week I have \"work\" :('\n",
    "        ]\n",
    "    )\n",
    "assert_array_equal(targets[:5000], [1] * 5000)\n",
    "assert_array_equal(targets[5000:], [0] * 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, targets, test_size=0.2, random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses Random Forest classifier to make document classifications.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A list of strings.\n",
    "    y_train: A list of strings.\n",
    "    X_test: A list of strings.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    \n",
    "    tools = [('tf', TfidfVectorizer()), ('rf', RandomForestClassifier(random_state=random_state))]\n",
    "    clf = Pipeline(tools)\n",
    "    clf.set_params(tf__stop_words = 'english', \\\n",
    "                   tf__ngram_range=(1,3))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF prediction accuracy =  72.3%\n"
     ]
    }
   ],
   "source": [
    "clf, y_pred = train(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(\"RF prediction accuracy = {0:5.1f}%\".format(100.0 * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf, Pipeline)\n",
    "assert_is_instance(y_pred, np.ndarray)\n",
    "tf = clf.named_steps['tf']\n",
    "assert_is_instance(tf, TfidfVectorizer)\n",
    "assert_is_instance(clf.named_steps['rf'], RandomForestClassifier)\n",
    "assert_equal(tf.stop_words, 'english')\n",
    "assert_equal(tf.ngram_range, (1, 3))\n",
    "assert_equal(len(y_pred), len(y_test))\n",
    "assert_array_equal(y_pred[:10], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1])\n",
    "assert_array_equal(y_pred[-10:], [0, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
    "assert_almost_equal(score, 0.723)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timeline(user, since_id, max_id):\n",
    "    '''\n",
    "    Fetches 20 tweets from \"user\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    user: A string. The ID or screen name of a Twitter user.\n",
    "    since_id: An int. Returns only statuses with an ID greater than (that is, more recent than) the specified ID.\n",
    "    max_id: An int. Returns only statuses with an ID less than (that is, older than) or equal to the specified ID..\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of integers.\n",
    "    '''\n",
    "    \n",
    "    timeline=api.user_timeline(screen_name=user, since_id=since_id, max_id =max_id )\n",
    "    return timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeline1 = get_timeline('TheDemocrats', since_id =735495811841298432  ,max_id=  837326424117817346 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeline2 = get_timeline('GOP', since_id=  734118726795042817, max_id =834928725183586308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_equal(\n",
    "    [t.id for t in timeline1],\n",
    "    [837326424117817346,\n",
    "    837320785794564096,\n",
    "    837100935457488901,\n",
    "    837072132290949120,\n",
    "    837052049317588994,\n",
    "    837037094686031873,\n",
    "    837011510446682113,\n",
    "    836990720640749569,\n",
    "    836966617632342016,\n",
    "    836803847762886656,\n",
    "    836801033133260800,\n",
    "    836785330455998464,\n",
    "    836779989068558336,\n",
    "    836777446821281792,\n",
    "    836771651694039042,\n",
    "    836769183375458306,\n",
    "    836768477943836673,\n",
    "    836768098275495936,\n",
    "    836767367107645441,\n",
    "    836766862566387712]\n",
    "    )\n",
    "assert_equal(\n",
    "    [t.id for t in timeline2],\n",
    "    [834928725183586308,\n",
    "    834898073121861635,\n",
    "    834896078055014401,\n",
    "    834856145974153216,\n",
    "    834851413746413568,\n",
    "    834807922995712000,\n",
    "    834790862815125504,\n",
    "    834779274175512576,\n",
    "    834756446608879618,\n",
    "    834531775883911168,\n",
    "    834513243087523841,\n",
    "    834497491517263872,\n",
    "    834205062805196800,\n",
    "    834058475785351168,\n",
    "    833738748894535680,\n",
    "    833699482852327425,\n",
    "    833682386953056256,\n",
    "    833489605559275520,\n",
    "    833371582366175233,\n",
    "    833368197160136706])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(clf, timeline):\n",
    "    '''\n",
    "    Uses a classifier (\"clf\") to classify each tweet in\n",
    "    \"timeline\" as a positive tweet or a negative tweet.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf: A Pipeline instance.\n",
    "    timeline: A tweepy.models.ResultSet instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A numpy array.\n",
    "    '''\n",
    "    \n",
    "    messages = []\n",
    "    for tweet in timeline:\n",
    "        messages.append(tweet.text)\n",
    "    new_tweets = np.array(messages)\n",
    "    y_pred = clf.predict(new_tweets)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Democrats account has 3 positive tweets and 17 negative tweets.\n"
     ]
    }
   ],
   "source": [
    "pred1 = predict(clf, timeline1)\n",
    "print('{} has {} positive tweets and {} negative tweets.'.format(\n",
    "    'The Democrats account', (pred1 == 1).sum(), (pred1 == 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_is_instance(pred1, np.ndarray)\n",
    "assert_array_equal(\n",
    "     pred1,\n",
    "     [0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  \n",
    "      0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 1.,  0.]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GOP account has 14 positive tweets and 6 negative tweets.\n"
     ]
    }
   ],
   "source": [
    "pred2 = predict(clf, timeline2)\n",
    "print('{} has {} positive tweets and {} negative tweets.'.format(\n",
    "    'The GOP account', (pred2 == 1).sum(), (pred2 == 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_is_instance(pred2, np.ndarray)\n",
    "assert_array_equal(\n",
    "     pred2,\n",
    "     [1.,  1.,  1.,  1.,  0. , 1.,  0.,  0.,  1.,  0.,  \n",
    "      1.,  1.,  1.,  1.,  1.,  1.,  1.,  0., 0.,  1.]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
