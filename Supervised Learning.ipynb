{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_in, assert_is_not\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal, assert_index_equal\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('2001.csv', encoding='latin-1', usecols=(1, 2, 3, 5, 7, 15, 16, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local = df[df['Origin'] == 'ORD']\n",
    "local = local.drop('Origin', axis=1)\n",
    "local['Delayed'] = (local['DepDelay'] >= 15).astype(np.int) \n",
    "local = local.drop('DepDelay', axis=1).dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Month  DayofMonth  DayOfWeek  CRSDepTime  CRSArrTime  Distance  Delayed\n",
      "6367      1           1          1         951        1235       599        0\n",
      "6368      1           2          2         951        1235       599        0\n",
      "6369      1           3          3         951        1235       599        0\n",
      "6370      1           4          4         951        1235       599        1\n",
      "6371      1           5          5         951        1235       599        0\n"
     ]
    }
   ],
   "source": [
    "print(local.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(df, test_column, test_size, random_state):\n",
    "    '''\n",
    "    Uses sklearn.train_test_split to split \"df\" into a testing set and a test set.\n",
    "    The \"test_columns\" lists the column that we are trying to predict.\n",
    "    All columns in \"df\" except \"test_columns\" will be used for training.\n",
    "    The \"test_size\" should be between 0.0 and 1.0 and represents the proportion of the\n",
    "    dataset to include in the test split.\n",
    "    The \"random_state\" parameter is used in sklearn.train_test_split.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    test_columns: A list of strings\n",
    "    test_size: A float\n",
    "    random_state: A numpy.random.RandomState instance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple of pandas.DataFrames\n",
    "    '''\n",
    "    x=df.drop(test_column, axis=1)\n",
    "    y=df[test_column]\n",
    "    (X_train, X_test, y_train, y_test) = train_test_split(x, y, test_size=test_size,random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_valid, X_test, y_train_valid, y_test = split(\n",
    "    df=local,\n",
    "    test_column=['Delayed'],\n",
    "    test_size=0.2,\n",
    "    random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(X_train_valid, pd.DataFrame), True)\n",
    "assert_equal(isinstance(X_test, pd.DataFrame), True)\n",
    "assert_equal(isinstance(y_train_valid, pd.DataFrame), True)\n",
    "assert_equal(isinstance(y_test, pd.DataFrame), True)\n",
    "\n",
    "assert_equal(len(X_train_valid) - np.round(len(local) * 0.8) <= 1, True)\n",
    "assert_equal(len(X_test) - np.round(len(local) * 0.2) <= 1, True)\n",
    "assert_equal(len(y_train_valid) - np.round(len(local) * 0.8) <= 1, True)\n",
    "assert_equal(len(y_test) - np.round(len(local) * 0.2) <= 1, True)\n",
    "\n",
    "assert_index_equal(X_train_valid.columns, local.columns.drop('Delayed'))\n",
    "assert_index_equal(X_test.columns, local.columns.drop('Delayed'))\n",
    "assert_equal(y_train_valid.columns, pd.Index(['Delayed']))\n",
    "assert_equal(y_test.columns, pd.Index(['Delayed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = split(\n",
    "    df=X_train_valid.join(y_train_valid),\n",
    "        test_column=['Delayed'],\n",
    "    test_size=0.25,\n",
    "    random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_equal(len(X_train) - np.round(len(local) * 0.6) <= 1, True)\n",
    "assert_equal(len(X_valid) - np.round(len(local) * 0.2) <= 1, True)\n",
    "assert_equal(len(y_train) - np.round(len(local) * 0.6) <= 1, True)\n",
    "assert_equal(len(X_valid) - np.round(len(local) * 0.2) <= 1, True)\n",
    "\n",
    "assert_index_equal(X_train.index[:5], pd.Int64Index([5903153, 1200840, 4524718, 2419368, 4017270]))\n",
    "assert_index_equal(X_valid.index[:5], pd.Int64Index([722372, 3342898, 4673529,  896758, 1744337]))\n",
    "assert_index_equal(y_train.index, X_train.index)\n",
    "assert_index_equal(y_valid.index, X_valid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month           1\n",
      "DayofMonth      1\n",
      "DayOfWeek       1\n",
      "CRSDepTime    530\n",
      "CRSArrTime      1\n",
      "Distance       67\n",
      "Delayed         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(local.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month           12\n",
      "DayofMonth      31\n",
      "DayOfWeek        7\n",
      "CRSDepTime    2245\n",
      "CRSArrTime    2359\n",
      "Distance      4243\n",
      "Delayed          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(local.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    '''\n",
    "    Takes a dataframe and normlizes features to be in range [0, 1].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    new=(df-df.min())/(df.max()-df.min())\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month         0.0\n",
      "DayofMonth    0.0\n",
      "DayOfWeek     0.0\n",
      "CRSDepTime    0.0\n",
      "CRSArrTime    0.0\n",
      "Distance      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train_normal, X_valid_normal = map(normalize, [X_train, X_valid])\n",
    "print(X_train_normal.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month         1.0\n",
      "DayofMonth    1.0\n",
      "DayOfWeek     1.0\n",
      "CRSDepTime    1.0\n",
      "CRSArrTime    1.0\n",
      "Distance      1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train_normal.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'a': [0, 1, 2, 3, 4],\n",
    "    'b': [-50, -20, 10, 45, 50],\n",
    "    'c': [-200, 450, 100, 500, -500]\n",
    "    })\n",
    "\n",
    "test1 = normalize(df0)\n",
    "answer1 = pd.DataFrame({\n",
    "    'a': [0., 0.25, 0.5, 0.75, 1.],\n",
    "    'b': [0., 0.3, 0.6, 0.95, 1.],\n",
    "    'c': [0.3, 0.95, 0.6, 1., 0.]\n",
    "    })\n",
    "assert_frame_equal(test1, answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_knn(X, y, n_neighbors):\n",
    "    '''\n",
    "    Fits a $k$-Nearest Neighbors on the training data.\n",
    "    Returns the trained model (an `sklearn.neighbors.KNeighborsClassifier` object).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Training attributes.\n",
    "    y: A pandas.DataFrame. Truth labels.\n",
    "    n_neighbors: Number of neighbors to use in kNN.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An sklearn.neighbors.KNeighborsClassifier object.\n",
    "    '''\n",
    "    knc = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knc.fit(X, y)\n",
    "    return knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X_train = pd.DataFrame({\n",
    "    'a': np.random.rand(100),\n",
    "    'b': np.random.rand(100)\n",
    "    })\n",
    "test_y_train = pd.DataFrame({\n",
    "    'y': np.floor(np.random.rand(100) * 2)\n",
    "    })\n",
    "\n",
    "test2 = train_knn(test_X_train, test_y_train, 1)\n",
    "\n",
    "assert_equal(isinstance(test2, neighbors.KNeighborsClassifier), True)\n",
    "assert_equal(test2.n_neighbors, 1)\n",
    "assert_array_almost_equal(test2._fit_X, test_X_train)\n",
    "assert_array_equal(test2._y, test_y_train.values.ravel())\n",
    "\n",
    "# test with different n_neighbors\n",
    "test3 = train_knn(test_X_train, test_y_train, 5)\n",
    "assert_equal(test3.n_neighbors, 5)\n",
    "assert_array_almost_equal(test3._fit_X, test_X_train)\n",
    "assert_array_equal(test3._y, test_y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_knn(model, X):\n",
    "    '''\n",
    "    Fits an `sklearn.neighbors.KNeighborsClassifier` model on `X` and\n",
    "    returns a `numpy.ndarray` of predicted values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: An sklearn.neighbors.KNeighborsClassifier object.\n",
    "    X: pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame. Has one column \"Delayed\".\n",
    "    '''\n",
    "    z = model.predict(X)\n",
    "    prediction=pd.DataFrame(z,columns=['Delayed'])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test4_model = train_knn(X_train, y_train, 1)\n",
    "test4 = predict_knn(test4_model, X_valid)[:10]\n",
    "answer4 = pd.DataFrame({\n",
    "    'Delayed': [1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
    "    })\n",
    "\n",
    "assert_equal(isinstance(test4, pd.DataFrame), True)\n",
    "assert_frame_equal(test4, answer4)\n",
    "\n",
    "test5_model = train_knn(X_train, y_train, 3)\n",
    "test5 = predict_knn(test5_model, X_valid)[:10]\n",
    "answer5 = pd.DataFrame({\n",
    "    'Delayed': [1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    })\n",
    "assert_frame_equal(test5, answer5)\n",
    "\n",
    "test6_model = train_knn(X_train, y_train, 5)\n",
    "test6 = predict_knn(test6_model, X_valid)[:10]\n",
    "answer6 = pd.DataFrame({\n",
    "    'Delayed': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    })\n",
    "assert_frame_equal(test6, answer6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(X_train, X_valid, y_train, y_valid, start=1, end=51):\n",
    "    '''\n",
    "    Find accuracy scores for kNN classifers\n",
    "    with n_neighbors = start, start + 1, start + 2, ..., end - 1.\n",
    "    Returns a Numpy array of length end - start.\n",
    "    For example, if start=1 and end=4, then len(scores) = 3, and\n",
    "    scores[0] cooresponds to the accuracy of kNN with k=1,\n",
    "    scores[1] the accuracy of kNN with k=2, ..., and\n",
    "    scores[2] the accuracy of KNN with k=3.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A pandas.DataFrame\n",
    "    X_valid: A pandas.DataFrame\n",
    "    y_train: A pandas.DataFrame\n",
    "    y_valid: A pandas.DataFrame\n",
    "    start: An int.\n",
    "    end: An int.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A numpy.ndarray\n",
    "    '''\n",
    "    scores=np.empty(0)\n",
    "    for nbrs in range(start,end):\n",
    "        knc = neighbors.KNeighborsClassifier(n_neighbors=nbrs)\n",
    "        knc.fit(X_train, y_train)\n",
    "        score=knc.score(X_valid, y_valid)\n",
    "        scores=np.append(scores,score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test6 = compute_accuracy(X_train, X_valid, y_train, y_valid, 2, 5)\n",
    "assert_array_almost_equal(test6, [0.78034487, 0.74846536, 0.78298197])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model: k = 48\n"
     ]
    }
   ],
   "source": [
    "scores = compute_accuracy(X_train, X_valid, y_train, y_valid, 1, 51)\n",
    "k_best = np.argmax(scores) + 1\n",
    "print('The best model: k = {}'.format(k_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of k-Nearest Neighbors is 82.0%.\n"
     ]
    }
   ],
   "source": [
    "X_train_valid_normal, X_test_normal = map(normalize, [X_train_valid, X_test])\n",
    "\n",
    "final_model = train_knn(X_train_valid_normal, y_train_valid, n_neighbors=k_best)\n",
    "y_pred = predict_knn(final_model, X_test_normal)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy of k-Nearest Neighbors is {:2.1f}%.\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion(): \n",
    "    '''\n",
    "    Plots a confusion matrix using numpy.histogram2d() and seaborn.heatmap().\n",
    "    Returns a maptlotlib.axes.Axes instance.\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    names = ['Not delayed', 'Delayed']\n",
    "    pts, xe, ye = np.histogram2d(np.array(y_test).flatten(), np.array(y_pred).flatten(), bins=2)\n",
    "    pd_pts = pd.DataFrame(pts.astype(int), index=names, columns=names )\n",
    "    hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")\n",
    "    hm.axes.set_title('Confusion matrix for KNN (k=48)')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAFXCAYAAADNpmV/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nshQREbFDyVJERMQOJUsRERE7/h8ylqBDmnarUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1179aae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plot_confusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(ax, mpl.axes.Axes), True, msg=\"Your function should return a matplotlib.axes.Axes object.\")\n",
    "\n",
    "texts = [t.get_text() for t in ax.texts]\n",
    "assert_equal(texts, ['10558', '3370', '52604', '1725'])\n",
    "             \n",
    "x_tick_labels = [l.get_text() for l in ax.get_xticklabels()]\n",
    "y_tick_labels = [l.get_text() for l in ax.get_yticklabels()]\n",
    "assert_equal(y_tick_labels, ['Delayed', 'Not delayed'])\n",
    "\n",
    "assert_is_not(len(ax.title.get_text()), 0, msg=\"Your plot doesn't have a title.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_in, assert_is_not\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal, assert_index_equal\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('2001.csv', encoding='latin-1', usecols=(5, 8, 15, 16, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local = df[(df['Origin'] == 'ORD') & (df['UniqueCarrier'] == 'AA')]\n",
    "local = local.drop(['UniqueCarrier', 'Origin'], axis=1) \n",
    "local['Delayed'] = (local['DepDelay'] > 0).astype(np.int) \n",
    "local = local.drop('DepDelay', axis=1).dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delayed: 61932\n",
      "Not delayed: 44006\n"
     ]
    }
   ],
   "source": [
    "print('Delayed: {}\\nNot delayed: {}'.format(\n",
    "    (local.Delayed == 0).sum(),\n",
    "    (local.Delayed == 1).sum()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRSDepTime  Distance  Delayed\n",
      "398444        1905      1846        1\n",
      "398445        1905      1846        1\n",
      "398446        1905      1846        1\n",
      "398447        1905      1846        0\n",
      "398448        1905      1846        1\n"
     ]
    }
   ],
   "source": [
    "print(local.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(df, test_column, test_size, random_state):\n",
    "    '''\n",
    "    Uses sklearn.train_test_split to split \"df\" into a testing set and a test set.\n",
    "    The \"test_columns\" lists the column that we are trying to predict.\n",
    "    All columns in \"df\" except \"test_columns\" will be used for training.\n",
    "    The \"test_size\" should be between 0.0 and 1.0 and represents the proportion of the\n",
    "    dataset to include in the test split.\n",
    "    The \"random_state\" parameter is used in sklearn.train_test_split.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    test_columns: A list of strings\n",
    "    test_size: A float\n",
    "    random_state: A numpy.random.RandomState instance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple of numpy.ndarrays\n",
    "    '''\n",
    "    x=df.drop(test_column, axis=1)\n",
    "    y=df[test_column]\n",
    "    (X_train, X_test, y_train, y_test) = train_test_split(x, y, test_size=test_size,random_state=random_state)\n",
    "    X_train=np.array(X_train)\n",
    "    X_test=np.array(X_test)\n",
    "    y_train=np.array(y_train).flatten()\n",
    "    y_test=np.array(y_test).flatten()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(\n",
    "    df=local,\n",
    "    test_column=['Delayed'],\n",
    "    test_size=0.4,\n",
    "    random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples_train, n_features_train = X_train.shape\n",
    "n_samples_test, n_features_test = X_test.shape\n",
    "\n",
    "assert_equal(n_features_train, 2)\n",
    "assert_equal(n_features_test, 2)\n",
    "n_features = n_features_train\n",
    "\n",
    "assert_equal(np.abs(n_samples_train - np.round(len(local) * 0.6)) <= 1, True)\n",
    "assert_equal(np.abs(n_samples_test - np.round(len(local) * 0.4)) <= 1, True)\n",
    "\n",
    "assert_array_equal(X_train[:5],\n",
    "    np.array(\n",
    "        [[ 1500.,  1846.],\n",
    "         [ 1415.,   802.],\n",
    "         [ 1138.,   409.],\n",
    "         [ 1649.,   723.],\n",
    "         [ 1835.,   678.]]\n",
    "        ))\n",
    "assert_array_equal(X_test[:5],\n",
    "    np.array(\n",
    "        [[  645.,  1745.],\n",
    "         [  620.,   622.],\n",
    "         [  645.,  1745.],\n",
    "         [ 2040.,   678.],\n",
    "         [  835.,   268.]]\n",
    "        ))\n",
    "\n",
    "assert_array_equal(y_train[:10], np.array([1, 0, 1, 0, 1, 1, 1, 1, 0, 1]))\n",
    "assert_array_equal(y_test[:10], np.array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    '''\n",
    "    Takes a dataframe and normlizes features to be in range [0, 1].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    df_std =(df - df.min(axis=0)) / (df.max(axis=0) - df.min(axis=0))\n",
    "    scaled = df_std * 2 -1\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'a': [0, 1, 2, 3, 4],\n",
    "    'b': [-50, -20, 10, 45, 50],\n",
    "    'c': [-200, 450, 100, 500, -500]\n",
    "    })\n",
    "test1 = standardize(df0)\n",
    "answer1 = pd.DataFrame({\n",
    "        'a': [ -1., -0.5, 0., 0.5, 1.],\n",
    "        'b': [ -1., -0.4, 0.2, 0.9, 1.],\n",
    "        'c': [ -0.4, 0.9, 0.2, 1., -1.]\n",
    "    })\n",
    "assert_frame_equal(test1, answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = map(standardize, [X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(X_train, y_train, X_test, kernel):\n",
    "    '''\n",
    "    Fits a Support Vector Machine on the training data on \"X_train\" and \"y_train\".\n",
    "    Returns the predicted values on \"X_test\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A numpy.ndarray\n",
    "    y_train: A numpy.ndarray\n",
    "    X_test: A numpy.ndarray\n",
    "    kernel: A string that specifies kernel to be used in SVM\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model: An svm.SVC instance trained on \"X_train\" and \"y_train\"\n",
    "    y_pred: A numpy array. Values predicted by \"model\" on \"X_test\"\n",
    "    '''\n",
    "    svc = svm.SVC(kernel=kernel)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred=svc.predict(X_test)\n",
    "    return svc, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_t = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]\n",
    "y_train_t = [1, 1, 1, 2, 2, 2]\n",
    "X_test_t = [[-1, -1], [2, 2], [3, 2]]\n",
    "y_test_t = [1, 2, 2]\n",
    "\n",
    "model1, pred1 = fit_and_predict(X_train_t, y_train_t, X_test_t, 'linear')\n",
    "assert_equal(isinstance(model1, svm.SVC), True)\n",
    "assert_equal(model1.kernel, 'linear')\n",
    "assert_array_equal(pred1, y_test_t)\n",
    "\n",
    "model2, pred2 = fit_and_predict(X_train_t, y_train_t, X_test_t, 'rbf')\n",
    "assert_equal(model2.kernel, 'rbf')\n",
    "assert_array_equal(pred2, y_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf, y_pred = fit_and_predict(X_train_scaled, y_train, X_test_scaled, 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593779497829\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion():\n",
    "    '''\n",
    "    Plots a confusion matrix using numpy.histogram2d() and seaborn.heatmap().\n",
    "    Returns a maptlotlib.axes.Axes instance.\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    names = ['Not delayed', 'Delayed']\n",
    "    pts, xe, ye = np.histogram2d(np.array(y_test).flatten(), np.array(y_pred).flatten(), bins=2)\n",
    "    pd_pts = pd.DataFrame(pts.astype(int), index=names, columns=names )\n",
    "    hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")\n",
    "    hm.axes.set_title('Confusion matrix for SVM')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAFXCAYAAADNpmV/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b1fe9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plot_confusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(ax, mpl.axes.Axes), True, msg=\"Your function should return a matplotlib.axes.Axes object.\")\n",
    "\n",
    "texts = [t.get_text() for t in ax.texts]\n",
    "assert_equal(texts, ['14971', '2712', '22450', '2243'])\n",
    "             \n",
    "x_tick_labels = [l.get_text() for l in ax.get_xticklabels()]\n",
    "y_tick_labels = [l.get_text() for l in ax.get_yticklabels()]\n",
    "assert_equal(y_tick_labels, ['Delayed', 'Not delayed'])\n",
    "\n",
    "assert_is_not(len(ax.title.get_text()), 0, msg=\"Your plot doesn't have a title.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_by_class(X, y):\n",
    "    '''\n",
    "    Separate the training set (\"X\") by class value (\"y\")\n",
    "    so that we can calculate statistics for each class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A 2d numpy array\n",
    "    y: A 1d numpy array\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of 2d numpy arrays\n",
    "    '''\n",
    "    d=np.column_stack((X, y))\n",
    "    separated = {}\n",
    "    for i in range(len(d)):\n",
    "        vector = d[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector[:-1])\n",
    "    for j in range(len(separated)):\n",
    "        separated[j]=np.vstack(separated[j])\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [[2, 21], [1, 20], [3, 22]] )\n",
    "y_t = np.array( [1, 0, 1] )\n",
    "separated_t = separate_by_class(X_t, y_t)\n",
    "assert_array_equal(separated_t[0], np.array( [ [1, 20] ] ))\n",
    "assert_array_equal(separated_t[1], np.array( [ [2, 21], [3, 22] ] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_mean(array):\n",
    "    '''\n",
    "    Calculates the mean of each column, i.e. each attribute.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A 1d or 2d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1d or 2d numpy array\n",
    "    '''\n",
    "    mean=np.mean(array,axis=0)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_t = np.array( [ [1, 4, 7], [2, 5, 6], [3, 6, 8] ] )\n",
    "mean_t = calculate_mean(array_t)\n",
    "assert_array_equal(mean_t, np.array( [2., 5., 7.] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_stdev(array):\n",
    "    '''\n",
    "    Calculates the standard deviation (N-1 method) of each column, i.e. each attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A 1d or 2d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1d or 2d numpy array\n",
    "    '''\n",
    "    stdev=np.std(array,axis=0,ddof=1)\n",
    "    return stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_t = np.array( [ [1, 20, 14], [2, 21, 15], [3, 22, 16] ] )\n",
    "stdev_t = calculate_stdev(array_t)\n",
    "assert_array_equal(stdev_t, np.array( [1., 1., 1.] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [ [1, 20], [2, 21], [3, 22] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize(X):\n",
    "    '''\n",
    "    For a given list of instances (for a class value),\n",
    "    calculates the mean and the standard deviation for each attribute.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A 2d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 2d numpy array\n",
    "    '''\n",
    "    a=calculate_mean(X)\n",
    "    b=calculate_stdev(X)\n",
    "    summary=np.stack((a, b), axis=1)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [ [1, 20], [2, 21], [3, 22] ] )\n",
    "summary_t = summarize(X_t)\n",
    "assert_array_equal(summary_t, np.array( [ (2.0, 1.0), (21.0, 1.0) ] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [ [1, 20], [2, 21], [3, 22], [4, 22] ] )\n",
    "y_t = np.array( [1, 0, 1, 0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new=separate_by_class(X_t,y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.        ,   1.41421356],\n",
       "       [ 21.5       ,   0.70710678]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_by_class(X, y):\n",
    "    '''\n",
    "    Separates a training set into instances grouped by class.\n",
    "    It then calculates the summaries for each attribute.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A 2d numpy array. Represents training attributes.\n",
    "    y: A 1d numpy array. Represents class labels.\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of 2d numpy arrays. Uses each class label as keys\n",
    "    and summary for each class label as values.\n",
    "    '''\n",
    "    new=separate_by_class(X,y)\n",
    "    result={}\n",
    "    for i in range((len(new))):\n",
    "        result[i]=summarize(new[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [ [1, 20], [2, 21], [3, 22], [4, 22] ] )\n",
    "y_t = np.array( [1, 0, 1, 0] )\n",
    "summaries_t = summarize_by_class(X_t, y_t)\n",
    "assert_array_almost_equal(summaries_t[0], np.array( [ (3., 1.41421356), (21.5, 0.70710678) ] ))\n",
    "assert_array_almost_equal(summaries_t[1], np.array( [ (2., 1.41421356), (21.0, 1.41421356) ] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_log_probability(x, mean, stdev):\n",
    "    '''\n",
    "    Calculates log of Gaussian function to estimate\n",
    "    the log probability of a given attribute value.\n",
    "    Assume x, mean, stdev have the same length.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: A float or 1d numpy array\n",
    "    mean: A float or 1d numpy array\n",
    "    stdev: A float or 1d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float or 1d numpy array\n",
    "    '''\n",
    "    exponent = np.exp(-(np.power(x-mean,2)/(2*np.power(stdev,2))))\n",
    "    log_probability=np.log((1 / (np.sqrt(2*np.pi) * stdev)) * exponent)\n",
    "    return log_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_t = calculate_log_probability(np.array( [71.5] ), np.array( [73] ), np.array( [6.2] ))\n",
    "assert_array_almost_equal(array_t, np.array( [ -2.7727542144336588 ] ))\n",
    "\n",
    "array_t2 = calculate_log_probability(np.array( [1, 2] ), np.array( [3, 4] ), np.array( [5, 6] ))\n",
    "assert_array_almost_equal(array_t2, np.array( [-2.60837645, -2.76625356] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_class_log_probabilities(summaries, input_array):\n",
    "    '''\n",
    "    Combines the probabilities of all of the attribute values for a data instance\n",
    "    and comes up with a probability of the entire data instance belonging to the class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summaries: A dictionary of 2d numpy arrays\n",
    "    input_array: A numpy array of instances; each instance is a numpy array of attributes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of 1d numpy arrays of summed log probabilities\n",
    "    '''\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = []\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            for j in range(len(input_array)):\n",
    "                x = input_array[j]\n",
    "                y=calculate_log_probability(x, mean, stdev)\n",
    "                probabilities[classValue].append(y)\n",
    "    for k in range(len(probabilities)):\n",
    "        probabilities[k]=np.vstack(probabilities[k]).flatten()\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summaries_t = {0: np.array( [ (1, 0.5) ]), 1: np.array( [ (20, 5.0) ] )}\n",
    "input_t = np.array( [[1.1]] )\n",
    "log_probabilities = calculate_class_log_probabilities(summaries_t, input_t)\n",
    "assert_array_almost_equal(log_probabilities[0], np.array( [-0.24579135264472743] ))\n",
    "assert_array_almost_equal(log_probabilities[1], np.array( [-9.6725764456387715] ))\n",
    "\n",
    "input_t2 = np.array( [[4], [.9], [0]] )\n",
    "log_probabilities2 = calculate_class_log_probabilities(summaries_t, input_t2)\n",
    "assert_array_almost_equal(log_probabilities2[0], np.array( [-18.225791352644727, -0.24579135264472729, -2.2257913526447273] ))\n",
    "assert_array_almost_equal(log_probabilities2[1], np.array( [-7.6483764456387728, -9.8245764456387743, -10.528376445638774] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(summaries, input_array):\n",
    "    '''\n",
    "    Calculates the probability of each data instance belonging to each class value,\n",
    "    looks for the largest probability, and return the associated class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    summaries: A dictionary of numpy arrays\n",
    "    input_array: A numpy array of instances; each instance is a numpy array of attributes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1d numpy array\n",
    "    '''\n",
    "    prob = calculate_class_log_probabilities(summaries, input_array)\n",
    "    new=pd.DataFrame(prob)\n",
    "    return np.array(new.idxmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summaries_t = {0: np.array( [ (1, 0.5) ] ), 1: np.array( [ (20, 5.0) ] )}\n",
    "input_t1 = np.array( [[1.1]] )\n",
    "result_t1 = predict(summaries_t, input_t1)\n",
    "assert_array_equal(result_t1, np.array( [0.] ))\n",
    "\n",
    "test_set_t2 = np.array( [[1.1], [19.1]] )\n",
    "result_t2 = predict(summaries_t, test_set_t2)\n",
    "assert_array_equal(result_t2, np.array( [0., 1.] ))\n",
    "\n",
    "test_set_t3 = np.array( [[4], [.9], [0]] )\n",
    "result_t3 = predict(summaries_t, test_set_t3)\n",
    "assert_array_equal(result_t3, np.array( [1., 0., 0.] ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
